{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Set-up"
      ],
      "metadata": {
        "id": "gTKNSQnK5lbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations & Data"
      ],
      "metadata": {
        "id": "w1tL2Wtn98y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies\n",
        "\n",
        "##### Set up SigLIP #####\n",
        "\n",
        "# Install the right jax version for TPU/GPU/CPU\n",
        "import os\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  raise \"TPU colab not supported.\"\n",
        "elif 'NVIDIA_PRODUCT_NAME' in os.environ:\n",
        "  !nvidia-smi\n",
        "import jax\n",
        "jax.devices()\n",
        "\n",
        "\n",
        "# Get latest version of big_vision codebase.\n",
        "!git clone --quiet --branch=main --depth=1 https://github.com/google-research/big_vision\n",
        "!cd big_vision && git pull --rebase --quiet\n",
        "!pip -q install -r big_vision/big_vision/requirements.txt\n",
        "\n",
        "# Gives us ~2x faster gsutil cp to get the model checkpoints.\n",
        "!pip3 -q install --no-cache-dir -U crcmod\n",
        "\n",
        "%cd big_vision\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import ml_collections\n",
        "\n",
        "from google.colab.output import _publish as publish\n",
        "\n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "##### Set up Alibi Detect (UOD) #####\n",
        "\n",
        "!pip install alibi-detect\n",
        "!pip install easyfsl\n",
        "import os\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import InputLayer, Conv2D, Dense, Reshape, Conv2DTranspose, Flatten\n",
        "from tqdm import tqdm\n",
        "from easyfsl.datasets import EasySet\n",
        "from torchvision import transforms\n",
        "from alibi_detect.od import OutlierAE\n",
        "from alibi_detect.saving import save_detector, load_detector"
      ],
      "metadata": {
        "id": "5TUsf8oJ8CsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive for data\n",
        "#@markdown If you don't have data, try making an example flag in MS paint.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5ImqpX2p8t9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select Model Settings"
      ],
      "metadata": {
        "id": "no5_0Z5Z92wN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select SigLIP Model Settings\n",
        "\n",
        "# Various settings for our SigLIP model\n",
        "# VARIANT, RES = 'B/16', 224\n",
        "# VARIANT, RES = 'B/16', 256\n",
        "# VARIANT, RES = 'B/16', 384\n",
        "# VARIANT, RES = 'B/16', 512\n",
        "# VARIANT, RES = 'L/16', 256\n",
        "VARIANT, RES = 'L/16', 384\n",
        "# VARIANT, RES = 'So400m/14', 224\n",
        "# VARIANT, RES = 'So400m/14', 384\n",
        "# VARIANT, RES = 'B/16-i18n', 256\n",
        "\n",
        "CKPT, TXTVARIANT, EMBDIM, SEQLEN, VOCAB = {\n",
        "    ('B/16', 224): ('webli_en_b16_224_63724782.npz', 'B', 768, 64, 32_000),\n",
        "    ('B/16', 256): ('webli_en_b16_256_60500360.npz', 'B', 768, 64, 32_000),\n",
        "    ('B/16', 384): ('webli_en_b16_384_68578854.npz', 'B', 768, 64, 32_000),\n",
        "    ('B/16', 512): ('webli_en_b16_512_68580893.npz', 'B', 768, 64, 32_000),\n",
        "    ('L/16', 256): ('webli_en_l16_256_60552751.npz', 'L', 1024, 64, 32_000),\n",
        "    ('L/16', 384): ('webli_en_l16_384_63634585.npz', 'L', 1024, 64, 32_000),\n",
        "    ('So400m/14', 224): ('webli_en_so400m_224_57633886.npz', 'So400m', 1152, 16, 32_000),\n",
        "    ('So400m/14', 384): ('webli_en_so400m_384_58765454.npz', 'So400m', 1152, 64, 32_000),\n",
        "    ('B/16-i18n', 256): ('webli_i18n_b16_256_66117334.npz', 'B', 768, 64, 250_000),\n",
        "}[VARIANT, RES]\n",
        "\n",
        "# It is significantly faster to first copy the checkpoint (30s vs 8m30 for B and 1m vs ??? for L)\n",
        "!test -f /tmp/{CKPT} || gsutil cp gs://big_vision/siglip/{CKPT} /tmp/\n",
        "\n",
        "if VARIANT.endswith('-i18n'):\n",
        "  VARIANT = VARIANT[:-len('-i18n')]\n",
        "\n",
        "import big_vision.models.proj.image_text.two_towers as model_mod\n",
        "\n",
        "model_cfg = ml_collections.ConfigDict()\n",
        "model_cfg.image_model = 'vit'  # TODO(lbeyer): remove later, default\n",
        "model_cfg.text_model = 'proj.image_text.text_transformer'  # TODO(lbeyer): remove later, default\n",
        "model_cfg.image = dict(variant=VARIANT, pool_type='map')\n",
        "model_cfg.text = dict(variant=TXTVARIANT, vocab_size=VOCAB)\n",
        "model_cfg.out_dim = (None, EMBDIM)  # (image_out_dim, text_out_dim)\n",
        "model_cfg.bias_init = -10.0\n",
        "model_cfg.temperature_init = 10.0\n",
        "\n",
        "model = model_mod.Model(**model_cfg)\n",
        "\n",
        "# Using `init_params` is slower but will lead to `load` below performing sanity-checks.\n",
        "# init_params = jax.jit(model.init, backend=\"cpu\")(jax.random.PRNGKey(42), jnp.zeros([1, RES, RES, 3], jnp.float32), jnp.zeros([1, SEQLEN], jnp.int32))['params']\n",
        "init_params = None  # Faster but bypasses loading sanity-checks.\n",
        "\n",
        "params = model_mod.load(init_params, f'/tmp/{CKPT}', model_cfg)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7trPcxBh9Wkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Trained UOD Model\n",
        "\n",
        "# Change to match your mounted drive layout\n",
        "PROJECT_BASE_PATH = \"/content/drive/MyDrive/CS 229 Project\"  # I know it says CS 229, I was lazy to move the new model away from the data\n",
        "saved_detector_name = \"outlier_save\"\n",
        "saved_detector_path = os.path.join(PROJECT_BASE_PATH, saved_detector_name)\n",
        "\n",
        "# Load detector\n",
        "outlier_detector = load_detector(saved_detector_path)"
      ],
      "metadata": {
        "id": "cL6JCtEg-EY_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Models for Use"
      ],
      "metadata": {
        "id": "zB04gbdJ-mQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tokenize and embed texts (SigLIP)\n",
        "\n",
        "import big_vision.pp.builder as pp_builder\n",
        "import big_vision.pp.ops_general\n",
        "import big_vision.pp.ops_image\n",
        "import big_vision.pp.ops_text\n",
        "import PIL\n",
        "import os\n",
        "import random\n",
        "\n",
        "texts = countries_and_flags = [\n",
        "    \"Afghanistan flag\", \"Albania flag\", \"Algeria flag\", \"Andorra flag\", \"Angola flag\",\n",
        "    \"Antigua and Barbuda flag\", \"Argentina flag\", \"Armenia flag\", \"Australia flag\", \"Austria flag\",\n",
        "    \"Azerbaijan flag\", \"Bahamas flag\", \"Bahrain flag\", \"Bangladesh flag\", \"Barbados flag\",\n",
        "    \"Belarus flag\", \"Belgium flag\", \"Belize flag\", \"Benin flag\", \"Bhutan flag\",\n",
        "    \"Bolivia flag\", \"Bosnia and Herzegovina flag\", \"Botswana flag\", \"Brazil flag\", \"Brunei flag\",\n",
        "    \"Bulgaria flag\", \"Burkina Faso flag\", \"Burundi flag\", \"Cambodia flag\", \"Cameroon flag\",\n",
        "    \"Canada flag\", \"Cape Verde flag\", \"Central African Republic flag\", \"Chad flag\",\"Chile flag\",\n",
        "    \"China flag\", \"Colombia flag\", \"Comoros flag\", \"Costa Rica flag\", \"Croatia flag\",\n",
        "    \"Cuba flag\", \"Cyprus flag\", \"Czechia flag\", \"Democratic Republic of the Congo flag\", \"Denmark flag\",\n",
        "    \"Djibouti flag\", \"Dominica flag\", \"Dominican Republic flag\", \"East Timor flag\", \"Ecuador flag\",\n",
        "    \"Egypt flag\", \"El Salvador flag\", \"Equatorial Guinea flag\", \"Eritrea flag\", \"Estonia flag\",\n",
        "    \"Eswatini flag\", \"Ethiopia flag\", \"Fiji flag\", \"Finland flag\", \"France flag\",\n",
        "    \"Gabon flag\", \"Gambia flag\", \"Georgia flag\", \"Germany flag\", \"Ghana flag\",\n",
        "    \"Greece flag\", \"Grenada flag\", \"Guatemala flag\", \"Guinea flag\", \"Guinea Bissau flag\",\n",
        "    \"Guyana flag\", \"Haiti flag\", \"Honduras flag\", \"Hungary flag\", \"Iceland flag\",\n",
        "    \"India flag\", \"Indonesia flag\", \"Iran flag\", \"Iraq flag\", \"Ireland flag\",\n",
        "    \"Israel flag\", \"Italy flag\", \"Jamaica flag\", \"Japan flag\", \"Jordan flag\",\n",
        "    \"Kazakhstan flag\", \"Kenya flag\", \"Kiribati flag\", \"Korea North flag\", \"Korea South flag\",\n",
        "    \"Kosovo flag\", \"Kuwait flag\", \"Kyrgyzstan flag\", \"Laos flag\", \"Latvia flag\",\n",
        "    \"Lebanon flag\", \"Lesotho flag\", \"Liberia flag\", \"Libya flag\", \"Liechtenstein flag\",\n",
        "    \"Lithuania flag\", \"Luxembourg flag\", \"Madagascar flag\", \"Malawi flag\", \"Malaysia flag\",\n",
        "    \"Maldives flag\", \"Mali flag\", \"Malta flag\", \"Marshall Islands flag\", \"Mauritania flag\",\n",
        "    \"Mauritius flag\", \"Mexico flag\", \"Micronesia flag\", \"Moldova flag\", \"Monaco flag\",\n",
        "    \"Mongolia flag\", \"Montenegro flag\", \"Morocco flag\", \"Mozambique flag\", \"Myanmar flag\",\n",
        "    \"Namibia flag\", \"Nauru flag\", \"Nepal flag\",\"Netherlands flag\", \"New Zealand flag\",\n",
        "    \"Nicaragua flag\", \"Niger flag\", \"Nigeria flag\", \"North Macedonia flag\", \"Norway flag\",\n",
        "    \"Oman flag\", \"Pakistan flag\", \"Palau flag\", \"Panama flag\", \"Papua New Guinea flag\",\n",
        "    \"Paraguay flag\", \"Peru flag\", \"Philippines flag\", \"Poland flag\", \"Portugal flag\",\n",
        "    \"Qatar flag\", \"Republic of the Congo flag\", \"Romania flag\", \"Russia flag\", \"Rwanda flag\",\n",
        "    \"Saint Kitts and Nevis flag\", \"Saint Lucia flag\", \"Saint Vincent and the Grenadines flag\", \"Samoa flag\", \"San Marino flag\",\n",
        "    \"Sao Tome and Principe flag\", \"Saudi Arabia flag\", \"Senegal flag\", \"Serbia flag\", \"Seychelles flag\",\n",
        "    \"Sierra Leone flag\", \"Singapore flag\", \"Slovakia flag\", \"Slovenia flag\", \"Solomon Islands flag\",\n",
        "    \"Somalia flag\", \"South Africa flag\", \"South Sudan flag\", \"Spain flag\", \"Sri Lanka flag\",\n",
        "    \"State of Palestine flag\", \"Sudan flag\", \"Suriname flag\", \"Sweden flag\", \"Switzerland flag\",\n",
        "    \"Syria flag\", \"Taiwan flag\", \"Tajikistan flag\", \"Tanzania flag\", \"Thailand flag\",\n",
        "    \"Togo flag\", \"Tonga flag\", \"Trinidad and Tobago flag\", \"Tunisia flag\", \"Turkey flag\",\n",
        "    \"Turkmenistan flag\", \"Tuvalu flag\", \"Uganda flag\", \"Ukraine flag\", \"United Arab Emirates flag\",\n",
        "    \"United Kingdom flag\", \"United States of America flag\", \"Uruguay flag\", \"Uzbekistan flag\", \"Vanuatu flag\",\n",
        "    \"Vatican City flag\", \"Venezuela flag\", \"Vietnam flag\", \"Yemen flag\", \"Zambia flag\",\n",
        "    \"Zimbabwe flag\", \"Solid square of color\", \"Creative flag\"\n",
        "]\n",
        "\n",
        "TOKENIZERS = {\n",
        "    32_000: 'c4_en',\n",
        "    250_000: 'mc4',\n",
        "}\n",
        "\n",
        "pp_txt = pp_builder.get_preprocess_fn(f'tokenize(max_len={SEQLEN}, model=\"{TOKENIZERS[VOCAB]}\", eos=\"sticky\", pad_value=1, inkey=\"text\")')\n",
        "txts = np.array([pp_txt({'text': text})['labels'] for text in texts])\n",
        "_, ztxt, out = model.apply({'params': params}, None, txts)\n",
        "\n",
        "print(txts.shape, ztxt.shape)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dA_xmjjE-lhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Sifting"
      ],
      "metadata": {
        "id": "VBMWx4tH53nA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Random Image\n",
        "#@markdown You should replace this with your own images and code.\n",
        "#@markdown It is fine to just directly upload and use your own flags instead\n",
        "#@markdown of random selection.\n",
        "\n",
        "##### Random Generation #####\n",
        "import json\n",
        "import random\n",
        "\n",
        "\"\"\"\n",
        "# For testing purposes\n",
        "\n",
        "labeled_data_routes_path = \"/final_data.json\"\n",
        "with open(PROJECT_BASE_PATH + labeled_data_routes_path, 'r') as in_fp:\n",
        "  final_data = json.load(in_fp)\n",
        "\"\"\"\n",
        "\n",
        "data_base_path = PROJECT_BASE_PATH + \"/data/\"\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "# Get all of our images in the form of (containing_folder_path, file_path)\n",
        "# ex. (folder_1/folder_2/, image_name.png)\n",
        "# Useful for testing versus final data where entry keys are just the local path.\n",
        "for folder_idx in range(11):\n",
        "  files = os.listdir(data_base_path + f\"{folder_idx}_test/\")\n",
        "  for file_path in files:\n",
        "    image_paths.append((data_base_path + f\"{folder_idx}_test/\", file_path))\n",
        "\n",
        "image_duo = random.choice(image_paths)\n",
        "image = PIL.Image.open(image_duo[0] + image_duo[1])\n",
        "#############################\n",
        "\n",
        "##### Loaded Image #####\n",
        "\"\"\"\n",
        "image_path = ...\n",
        "PIL.Image.open(image_path)\n",
        "\"\"\"\n",
        "########################"
      ],
      "metadata": {
        "cellView": "form",
        "id": "guAOy6IPA8dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Apply SigLIP\n",
        "\n",
        "# Pre-process\n",
        "pp_img = pp_builder.get_preprocess_fn(f'resize({RES})|value_range(-1, 1)')\n",
        "img = np.array([pp_img({'image': np.array(image)})['image']])\n",
        "\n",
        "# Apply SigLIP\n",
        "zimg, _, out = model.apply({'params': params}, img, None)\n",
        "probs = jax.nn.sigmoid(zimg @ ztxt.T * out['t'] + out['b'])\n",
        "\n",
        "# Extract prediction\n",
        "predicted_labels = []\n",
        "corresponding_probs = []\n",
        "for i in range(len(probs)):\n",
        "  prob = probs[i]\n",
        "  indices = np.where(prob > 0.6)[0]\n",
        "  predicted_labels.append([])\n",
        "  corresponding_probs.append([])\n",
        "  if indices.any():\n",
        "    for index in indices:\n",
        "      predicted_labels[i].append(texts[index])\n",
        "      corresponding_probs[i].append(float(probs[i, index]))\n",
        "  else:\n",
        "    predicted_labels[i].append(\"edge\")\n",
        "\n",
        "prediction = predicted_labels[0][0]"
      ],
      "metadata": {
        "id": "a4TVU7fw5lFf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Edge-Case Handling"
      ],
      "metadata": {
        "id": "dACmcNhp55Z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run UOD\n",
        "if prediction == 'edge':\n",
        "  # Apply UOD\n",
        "  results = outlier_detector.predict([img],\n",
        "                                    outlier_type=\"instance\",\n",
        "                                    return_feature_score=True,\n",
        "                                    return_instance_score=True)\n",
        "\n",
        "  # Extract instance score to gauge outlier vs inlier\n",
        "  selected_threshold = 0.05  # Manual threshold, can change\n",
        "  outlier = results[\"data\"][\"instance_score\"][0] >= selected_threshold\n",
        "\n",
        "  # Make the decision in this case: creativite flag versus bug\n",
        "  prediction = \"creative\" if outlier else \"bug\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "WusWYYmWD-lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Demo Visual (Set-up Code)\n",
        "from IPython.display import Javascript\n",
        "\n",
        "DEMO_IMG_SIZE = 96\n",
        "\n",
        "import base64\n",
        "import io\n",
        "\n",
        "def bv2rgb(bv_img):\n",
        "  return (bv_img * 127.5 + 127.5).astype(np.uint8)\n",
        "\n",
        "def html_img(*, enc_img=None, pixels=None, id=None, size=100, max_size=None, max_height=None, style=\"\"):\n",
        "  if enc_img is None and pixels is not None:\n",
        "    with io.BytesIO() as buf:\n",
        "      PIL.Image.fromarray(np.asarray(pixels)).save(buf, format=\"JPEG\")\n",
        "      enc_img = buf.getvalue()\n",
        "\n",
        "  img_data = base64.b64encode(np.ascontiguousarray(enc_img)).decode('ascii')\n",
        "\n",
        "  id_spec = f'id={id}' if id else ''\n",
        "  if size is not None:\n",
        "    style_spec = f'style=\"{style}; width: {size}px; height: {size}px\"'\n",
        "  elif max_size is not None:\n",
        "    style_spec = f'style=\"{style}; width: auto; height: auto; max-width: {max_size}px; max-height: {max_size}px;\"'\n",
        "  elif max_height is not None:\n",
        "    style_spec = f'style=\"{style}; object-fit: cover; width: auto; height: {max_height}px;\"'\n",
        "  else: style_spec = ''\n",
        "\n",
        "  return f'<img {id_spec} {style_spec} src=\"data:image/png;base64,{img_data}\"/>'\n",
        "\n",
        "\n",
        "def make_table(zimg, ztxt, out):\n",
        "  # The default learnable bias is a little conservative. Play around with it!\n",
        "  t, b = out['t'].item(), out['b'].item()\n",
        "  tempered_logits = zimg @ ztxt.T * t\n",
        "  probs = 1 / (1 + np.exp(-tempered_logits - b))\n",
        "  publish.javascript(f\"var logits = {tempered_logits.tolist()};\")\n",
        "\n",
        "  def color(p):\n",
        "    return mpl.colors.rgb2hex(mpl.cm.Greens(p / 2)) if p >= 0.01 else \"transparent\"\n",
        "\n",
        "  publish.javascript(f\"var cmap = {[color(x) for x in np.linspace(0, 1, 50)]};\")\n",
        "  def cell(x, iimg, itxt):\n",
        "    return f\"<td id=td_{iimg}_{itxt} style=background-color:{color(x)} class=pct><pre id=p_{iimg}_{itxt}>{x * 100:>4.0f}%</pre>\"\n",
        "\n",
        "  html = f'''\n",
        "  <p>\n",
        "  <label for=b>Bias value:</label>\n",
        "  <input id=b type=range min=-15 max=0 step=0.1 name=b value={b} style=vertical-align:middle>\n",
        "  <output id=value></output>\n",
        "  </p>\n",
        "  '''\n",
        "\n",
        "  html += \"<table>\\n\"\n",
        "  html += \"<tr>\"\n",
        "  html += \"\".join([f\"<td style='width:{DEMO_IMG_SIZE}px;line-height:0'>\" + html_img(pixels=bv2rgb(img), size=DEMO_IMG_SIZE) for img in imgs])\n",
        "  html += \"<td>\"\n",
        "  # for itxt, txt in enumerate(texts):\n",
        "  #   html += f\"<tr>\" + \"\".join([cell(probs[iimg, itxt], iimg, itxt) for iimg in range(len(imgs))]) + f\"<td class=txt>{txt}\"\n",
        "\n",
        "  publish.css(r\"\"\"\n",
        "  table {\n",
        "    border-collapse: collapse;\n",
        "  }\n",
        "\n",
        "  tr {\n",
        "    border: 1px transparent;\n",
        "  }\n",
        "\n",
        "  tr:nth-child(odd) {\n",
        "    background-color: #F5F5F5;\n",
        "  }\n",
        "\n",
        "  tr:hover {\n",
        "    background-color: lightyellow;\n",
        "    border: 1px solid black;\n",
        "  }\n",
        "\n",
        "  td.pct {\n",
        "    text-align: center;\n",
        "  }\n",
        "  \"\"\")\n",
        "  publish.html(html)\n",
        "\n",
        "  # JS code to compute and write all probs from the logits.\n",
        "  display(Javascript('''\n",
        "  function update(b) {\n",
        "    for(var iimg = 0; iimg < logits.length; iimg++) {\n",
        "      for(var itxt = 0; itxt < logits[iimg].length; itxt++) {\n",
        "        const el = document.getElementById(`p_${iimg}_${itxt}`);\n",
        "        const p = Math.round(100 / (1 + Math.exp(-logits[iimg][itxt] - b)));\n",
        "        const pad = p < 10.0 ? '  ' : p < 100.0 ? ' ' : ''\n",
        "        el.innerHTML = pad + (p).toFixed(0) + '%';\n",
        "\n",
        "        const td = document.getElementById(`td_${iimg}_${itxt}`);\n",
        "        const c = cmap[Math.round(p / 100 * (cmap.length - 1))];\n",
        "        td.style.backgroundColor = c;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  '''))\n",
        "\n",
        "  # JS code to connect the bias value slider\n",
        "  display(Javascript('''\n",
        "  const value = document.querySelector(\"#value\");\n",
        "  const input = document.querySelector(\"#b\");\n",
        "  value.textContent = input.value;\n",
        "  input.addEventListener(\"input\", (event) => {\n",
        "    value.textContent = event.target.value;\n",
        "    update(event.target.value);\n",
        "  });\n",
        "  '''))\n",
        "\n",
        "  # Make the cell output as large as the table to avoid annoying scrollbars.\n",
        "  display(Javascript(f'update({b})'))\n",
        "  display(Javascript('google.colab.output.resizeIframeToContent()'))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mtVxxn9uGGNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo Visual\n",
        "make_table(zimg, ztxt, out)\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "bQUiFSx1GW0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Flag Feedback\n",
        "Set the variables to generate feedback based on the classification result and code snippet."
      ],
      "metadata": {
        "id": "3SVfv7X45lxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define API calls\n",
        "openai_api_key = userdata.get(\"openai_api_key\")\n",
        "\n",
        "def get_headers(api_key):\n",
        "  request_headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "  return request_headers\n",
        "\n",
        "def get_classification_payload(flag_result, flag_code_snippet):\n",
        "\n",
        "    message = f\"\"\"Q: This is an image of the Indian Flag created by the following code snippet. How could they improve it:\n",
        "    A:\n",
        "    Saffron (not orange): The top band of the Indian flag is saffron in color, not pure orange. You might need to find the right RGB code for saffron.\n",
        "\n",
        "    Wheel (Ashoka Chakra): In the center of the white band, there is a navy blue wheel with 24 spokes, known as the Ashoka Chakra. In your current code, you've drawn a blue oval, but for an accurate representation, you need a circular shape (not an oval), and it should have 24 spokes.\n",
        "\n",
        "    Dimensions: The actual Indian flag has a proportion of 2:3 (height:width), which seems to be followed in your current code.\n",
        "\n",
        "    This is an image of the {flag_result} created by the following code snippet {flag_code_snippet}. How could they improve it:\n",
        "    \"\"\"\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4-vision-preview\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": message\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 300\n",
        "    }\n",
        "\n",
        "    return payload\n",
        "\n",
        "def make_classification_request(flag_result, flag_code_snippet, api_key):\n",
        "  response = requests.post(\"https://api.openai.com/v1/chat/completions\",\n",
        "                            headers=get_headers(api_key),\n",
        "                            json=get_classification_payload(flag_result, flag_code_snippet))\n",
        "\n",
        "  return response.json()"
      ],
      "metadata": {
        "id": "fap85tKF42QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWJAHW1F3xAC"
      },
      "outputs": [],
      "source": [
        "#@title Request for feedback\n",
        "flag_classification = prediction\n",
        "code_snippet = \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = make_classification_request(flag_classification, code_snippet)"
      ]
    }
  ]
}