{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Set-up"
      ],
      "metadata": {
        "id": "-LM0icWOyDsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.0 Installations"
      ],
      "metadata": {
        "id": "vfdF0oB_yD_w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y1h3CzkwpGG"
      },
      "outputs": [],
      "source": [
        "!pip install easyfsl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Base Imports"
      ],
      "metadata": {
        "id": "Q5eSkwgWyPwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "nxtrVsCyyPGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Helper Functions & Necessary Data"
      ],
      "metadata": {
        "id": "1ybbzgKJySbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get(\"openai_api_key\")\n",
        "\n",
        "def get_headers(api_key):\n",
        "  request_headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "  return request_headers\n",
        "\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "def get_classification_payload(image_path):\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4-vision-preview\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": \"Classify this flag's country (or 'edge' if it is not a country) and creative complexity (on a scale 0-10, with blank flags being a 0, the Indonesian flag being a 2, and the American flag being a 10. Please format the response in the form of '{Country} {Creative Complexity}.'\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/jpeg;base64,{encode_image(image_path)}\"\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 300\n",
        "    }\n",
        "\n",
        "    return payload\n",
        "\n",
        "def make_classification_request(image_path, api_key):\n",
        "  response = requests.post(\"https://api.openai.com/v1/chat/completions\",\n",
        "                            headers=get_headers(api_key),\n",
        "                            json=get_classification_payload(image_path))\n",
        "\n",
        "  return response.json()"
      ],
      "metadata": {
        "id": "oQlrQ3ZlyCWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Data Loading\n",
        "\n",
        "Note: We don't need to train GPT for this task. We also as of 12/15/2023 cannot fine-tune the model."
      ],
      "metadata": {
        "id": "qC_q73Vu0KAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the base path to specify where we are working\n",
        "PROJECT_BASE_PATH = \"/content/drive/MyDrive/CS 229 Project\"  # Change to match your mounted drive layout\n",
        "\n",
        "# Set paths for our test data with proper relation to our mounted drive\n",
        "TEST_PATH = os.path.join(PROJECT_BASE_PATH, \"all_complexities_easyset_test.json\")"
      ],
      "metadata": {
        "id": "dGxDQ_MEy2IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. (Run Once) Split Data\n",
        "You should not (and likely will get an error either way if you try to) repeat this step.\n",
        "\n",
        "Make sure you have all your files in hand so you do not have to reset your data and repeat this step."
      ],
      "metadata": {
        "id": "K14NkI650cFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You'll need to copy over your PROJECT_BASE_PATH to here as well\n",
        "safeguard = True\n",
        "\n",
        "if not safeguard:\n",
        "  !python /content/drive/MyDrive/\"CS 229 Project\"/create_easyset_data.py\n",
        "  !python /content/drive/MyDrive/\"CS 229 Project\"/create_train_test_easyset.py\n",
        "else:\n",
        "  print(\"Safeguard is active. Skipping data split.\")"
      ],
      "metadata": {
        "id": "EY4XNC3c0cWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. (Optional) Verify Data Paths"
      ],
      "metadata": {
        "id": "rrn11JRF0fnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{TEST_PATH = }\")"
      ],
      "metadata": {
        "id": "JH8dm4s60iUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Generate EasySet Data"
      ],
      "metadata": {
        "id": "thZkGNFC0mYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from easyfsl.datasets import EasySet\n",
        "from torchvision import transforms\n",
        "\n",
        "image_size = 80\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomResizedCrop(image_size),\n",
        "        transforms.ToTensor()\n",
        "        # ,transforms.Normalize(**{\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]})\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_set = EasySet(TEST_PATH, image_size=image_size, transform=test_transform)"
      ],
      "metadata": {
        "id": "zFAghFDB0nor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional) Validate Data"
      ],
      "metadata": {
        "id": "4-OZNZzg01BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set checks\n",
        "print(f\"{test_set.number_of_classes() = }\")\n",
        "print(f\"{len(test_set) = }\")"
      ],
      "metadata": {
        "id": "RPGD6Igd00sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Get Test Set"
      ],
      "metadata": {
        "id": "AxYBND0p09PO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Get our query images and labels\n",
        "data_roots = [os.path.join(PROJECT_BASE_PATH, \"data\", class_name + \"_test\") for class_name in test_set.class_names]\n",
        "image_paths, labels = test_set.list_data_instances(data_roots)"
      ],
      "metadata": {
        "id": "XiaZcSvt0850"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional) Check size"
      ],
      "metadata": {
        "id": "239rbgbt5CSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert(len(image_paths) == len(test_set))"
      ],
      "metadata": {
        "id": "SOmGpVXt3DS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.0 Run Comparisons"
      ],
      "metadata": {
        "id": "LXhmMOr_5av3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "\n",
        "predictions = {}\n",
        "\n",
        "RUN_SAFEGUARD = True\n",
        "\n",
        "if not RUN_SAFEGUARD:\n",
        "  for i in tqdm(range(len(image_paths))):\n",
        "    path = image_paths[i]\n",
        "\n",
        "    try:\n",
        "      response = make_classification_request(path, openai_api_key)\n",
        "      prediction = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "      country, complexity = prediction.split()\n",
        "\n",
        "      predictions[path] = {\"country\": country, \"complexity\": int(float(complexity))}\n",
        "\n",
        "    except:\n",
        "      print(path, \"had an error. Waiting and trying again\")\n",
        "      sleep(60)\n",
        "\n",
        "      try:\n",
        "        response = make_classification_request(path, openai_api_key)\n",
        "        prediction = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "        country, complexity = prediction.split()\n",
        "\n",
        "        predictions[path] = {\"country\": country, \"complexity\": int(float(complexity))}\n",
        "\n",
        "      except:\n",
        "        print(path, \"failed to resolve its error.\")\n",
        "else:\n",
        "  print(\"Run time safeguard for API calls is active. Skipping cell.\")"
      ],
      "metadata": {
        "id": "YSGY0CBf6JM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "PREDICTIONS_SAVE_PATH = \"chatgpt_predictions.json\"\n",
        "gpt_save_path = os.path.join(PROJECT_BASE_PATH, PREDICTIONS_SAVE_PATH)\n",
        "\n",
        "if not RUN_SAFEGUARD:\n",
        "  with open(gpt_save_path, 'w') as out_fp:\n",
        "    json.dump(predictions, out_fp, indent=4)\n",
        "\n",
        "else:\n",
        "  with open(gpt_save_path, 'r') as in_fp:\n",
        "    predictions = json.load(in_fp)"
      ],
      "metadata": {
        "id": "h1UF-D9l6Shf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.0 Evaluate\n"
      ],
      "metadata": {
        "id": "NHa6SyRT9ho1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Complexity"
      ],
      "metadata": {
        "id": "IvE2eHgVRPF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_correct = 0\n",
        "num_total = len(predictions)\n",
        "num_counted = len(predictions)\n",
        "\n",
        "for i in range(num_total):\n",
        "  try:\n",
        "    image_path = image_paths[i]\n",
        "\n",
        "    prediction = predictions[image_path][\"complexity\"]\n",
        "    y_complexity = labels[i]\n",
        "\n",
        "    if (y_complexity >= 2 and prediction >= 2) or (y_complexity < 2 and prediction < 2):\n",
        "      num_correct += 1\n",
        "  except:\n",
        "    num_counted -= 1\n",
        "\n",
        "print(f\"Num Correct: {num_correct}/{num_counted}\")\n",
        "print(f\"Accuracy: {num_correct / num_counted}\")"
      ],
      "metadata": {
        "id": "mf5Nnklg9jF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Country"
      ],
      "metadata": {
        "id": "UB99crzVRR4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_correct = 0\n",
        "num_total = len(predictions)\n",
        "num_counted = len(predictions)\n",
        "\n",
        "with open(os.path.join(PROJECT_BASE_PATH, \"final_data.json\")) as in_fp:\n",
        "  all_data = json.load(in_fp)\n",
        "\n",
        "for i in range(num_total):\n",
        "  try:\n",
        "    image_path = image_paths[i]\n",
        "\n",
        "    prediction = predictions[image_path][\"country\"]\n",
        "    cleaned_path = image_path[len(image_path) - image_path[::-1].find('/'):]\n",
        "    y_country = all_data[cleaned_path][\"country\"]\n",
        "\n",
        "    if y_country.lower() == prediction.lower():\n",
        "      num_correct += 1\n",
        "  except:\n",
        "    num_counted -= 1\n",
        "\n",
        "print(f\"Num Correct: {num_correct}/{num_counted}\")\n",
        "print(f\"Accuracy: {num_correct / num_counted}\")"
      ],
      "metadata": {
        "id": "L3C9CBxPRSLy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}