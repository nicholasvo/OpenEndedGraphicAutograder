{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# General information\n",
        "\n",
        "Example colab for SigLIP models described in [the SigLIP paper](https://arxiv.org/abs/2303.15343).\n",
        "\n",
        "**These models are not official Google products and were trained and released for research purposes.**\n",
        "\n",
        "If you find our model(s) useful for your research, consider citing\n",
        "\n",
        "```\n",
        "@article{zhai2023sigmoid,\n",
        "  title={Sigmoid loss for language image pre-training},\n",
        "  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},\n",
        "  journal={International Conference on Computer Vision ({ICCV})},\n",
        "  year={2023}\n",
        "}\n",
        "```\n",
        "\n",
        "If you use our released models in your products, we will appreciate any direct feedback. We are reachable by xzhai@google.com, basilm@google.com, akolesnikov@google.com and lbeyer@google.com.\n",
        "\n",
        "\n",
        "Only the models explicitly marked with `i18n` in the name are expected to perform reasonably well on non-english data."
      ],
      "metadata": {
        "id": "wR53lePHuiP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Environment setup\n",
        "#@markdown **IMPORTANT NOTE**: Modern jax (>0.4) does not support the Colab TPU\n",
        "#@markdown anymore, so don't select TPU runtime here. CPU and GPU work and are both fast enough.\n",
        "\n",
        "# Install the right jax version for TPU/GPU/CPU\n",
        "import os\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  raise \"TPU colab not supported.\"\n",
        "elif 'NVIDIA_PRODUCT_NAME' in os.environ:\n",
        "  !nvidia-smi\n",
        "import jax\n",
        "jax.devices()\n",
        "\n",
        "\n",
        "# Get latest version of big_vision codebase.\n",
        "!git clone --quiet --branch=main --depth=1 https://github.com/google-research/big_vision\n",
        "!cd big_vision && git pull --rebase --quiet\n",
        "!pip -q install -r big_vision/big_vision/requirements.txt\n",
        "# Gives us ~2x faster gsutil cp to get the model checkpoints.\n",
        "!pip3 -q install --no-cache-dir -U crcmod\n",
        "\n",
        "%cd big_vision\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import ml_collections\n",
        "\n",
        "from google.colab.output import _publish as publish\n",
        "\n",
        "#################\n",
        "\n",
        "!pip install alibi-detect\n",
        "!pip install easyfsl\n",
        "import os\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import InputLayer, Conv2D, Dense, Reshape, Conv2DTranspose, Flatten\n",
        "from tqdm import tqdm\n",
        "from easyfsl.datasets import EasySet\n",
        "from torchvision import transforms\n",
        "from alibi_detect.od import OutlierAE\n",
        "from alibi_detect.saving import save_detector, load_detector"
      ],
      "metadata": {
        "id": "kXSdSXVg2PAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive for data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Eg9Zi3Bg15Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choose and load model, perform inference"
      ],
      "metadata": {
        "id": "byHpmgAO6inM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select model settings\n",
        "# Pick your hero: (WHEN CHANGING THIS, RERUN IMAGE/TEXT EMBEDDING CELLS)\n",
        "# Give this cell 1-3mins.\n",
        "\n",
        "# Various settings for our SigLIP model\n",
        "# VARIANT, RES = 'B/16', 224\n",
        "# VARIANT, RES = 'B/16', 256\n",
        "# VARIANT, RES = 'B/16', 384\n",
        "# VARIANT, RES = 'B/16', 512\n",
        "# VARIANT, RES = 'L/16', 256\n",
        "VARIANT, RES = 'L/16', 384\n",
        "# VARIANT, RES = 'So400m/14', 224\n",
        "# VARIANT, RES = 'So400m/14', 384\n",
        "# VARIANT, RES = 'B/16-i18n', 256\n",
        "\n",
        "CKPT, TXTVARIANT, EMBDIM, SEQLEN, VOCAB = {\n",
        "    ('B/16', 224): ('webli_en_b16_224_63724782.npz', 'B', 768, 64, 32_000),\n",
        "    ('B/16', 256): ('webli_en_b16_256_60500360.npz', 'B', 768, 64, 32_000),\n",
        "    ('B/16', 384): ('webli_en_b16_384_68578854.npz', 'B', 768, 64, 32_000),\n",
        "    ('B/16', 512): ('webli_en_b16_512_68580893.npz', 'B', 768, 64, 32_000),\n",
        "    ('L/16', 256): ('webli_en_l16_256_60552751.npz', 'L', 1024, 64, 32_000),\n",
        "    ('L/16', 384): ('webli_en_l16_384_63634585.npz', 'L', 1024, 64, 32_000),\n",
        "    ('So400m/14', 224): ('webli_en_so400m_224_57633886.npz', 'So400m', 1152, 16, 32_000),\n",
        "    ('So400m/14', 384): ('webli_en_so400m_384_58765454.npz', 'So400m', 1152, 64, 32_000),\n",
        "    ('B/16-i18n', 256): ('webli_i18n_b16_256_66117334.npz', 'B', 768, 64, 250_000),\n",
        "}[VARIANT, RES]\n",
        "\n",
        "# It is significantly faster to first copy the checkpoint (30s vs 8m30 for B and 1m vs ??? for L)\n",
        "!test -f /tmp/{CKPT} || gsutil cp gs://big_vision/siglip/{CKPT} /tmp/\n",
        "\n",
        "if VARIANT.endswith('-i18n'):\n",
        "  VARIANT = VARIANT[:-len('-i18n')]\n",
        "\n",
        "import big_vision.models.proj.image_text.two_towers as model_mod\n",
        "\n",
        "model_cfg = ml_collections.ConfigDict()\n",
        "model_cfg.image_model = 'vit'  # TODO(lbeyer): remove later, default\n",
        "model_cfg.text_model = 'proj.image_text.text_transformer'  # TODO(lbeyer): remove later, default\n",
        "model_cfg.image = dict(variant=VARIANT, pool_type='map')\n",
        "model_cfg.text = dict(variant=TXTVARIANT, vocab_size=VOCAB)\n",
        "model_cfg.out_dim = (None, EMBDIM)  # (image_out_dim, text_out_dim)\n",
        "model_cfg.bias_init = -10.0\n",
        "model_cfg.temperature_init = 10.0\n",
        "\n",
        "model = model_mod.Model(**model_cfg)\n",
        "\n",
        "# Using `init_params` is slower but will lead to `load` below performing sanity-checks.\n",
        "# init_params = jax.jit(model.init, backend=\"cpu\")(jax.random.PRNGKey(42), jnp.zeros([1, RES, RES, 3], jnp.float32), jnp.zeros([1, SEQLEN], jnp.int32))['params']\n",
        "init_params = None  # Faster but bypasses loading sanity-checks.\n",
        "\n",
        "params = model_mod.load(init_params, f'/tmp/{CKPT}', model_cfg)\n",
        "\n",
        "######################\n",
        "\n",
        "# Set-up Outlier detection\n",
        "PROJECT_BASE_PATH = \"/content/drive/MyDrive/CS 229 Project\"  # Change to match your mounted drive layout\n",
        "saved_detector_name = \"outlier_save\"\n",
        "saved_detector_path = os.path.join(PROJECT_BASE_PATH, saved_detector_name)\n",
        "\n",
        "outlier_detector = load_detector(saved_detector_path)"
      ],
      "metadata": {
        "id": "0DsOabGD7MRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tokenize and embed texts\n",
        "\n",
        "import big_vision.pp.builder as pp_builder\n",
        "import big_vision.pp.ops_general\n",
        "import big_vision.pp.ops_image\n",
        "import big_vision.pp.ops_text\n",
        "import PIL\n",
        "import os\n",
        "import random\n",
        "\n",
        "texts = countries_and_flags = [\n",
        "    \"Afghanistan flag\",\n",
        "    \"Albania flag\",\n",
        "    \"Algeria flag\",\n",
        "    \"Andorra flag\",\n",
        "    \"Angola flag\",\n",
        "    \"Antigua and Barbuda flag\",\n",
        "    \"Argentina flag\",\n",
        "    \"Armenia flag\",\n",
        "    \"Australia flag\",\n",
        "    \"Austria flag\",\n",
        "    \"Azerbaijan flag\",\n",
        "    \"Bahamas flag\",\n",
        "    \"Bahrain flag\",\n",
        "    \"Bangladesh flag\",\n",
        "    \"Barbados flag\",\n",
        "    \"Belarus flag\",\n",
        "    \"Belgium flag\",\n",
        "    \"Belize flag\",\n",
        "    \"Benin flag\",\n",
        "    \"Bhutan flag\",\n",
        "    \"Bolivia flag\",\n",
        "    \"Bosnia and Herzegovina flag\",\n",
        "    \"Botswana flag\",\n",
        "    \"Brazil flag\",\n",
        "    \"Brunei flag\",\n",
        "    \"Bulgaria flag\",\n",
        "    \"Burkina Faso flag\",\n",
        "    \"Burundi flag\",\n",
        "    \"Cambodia flag\",\n",
        "    \"Cameroon flag\",\n",
        "    \"Canada flag\",\n",
        "    \"Cape Verde flag\",\n",
        "    \"Central African Republic flag\",\n",
        "    \"Chad flag\",\n",
        "    \"Chile flag\",\n",
        "    \"China flag\",\n",
        "    \"Colombia flag\",\n",
        "    \"Comoros flag\",\n",
        "    \"Costa Rica flag\",\n",
        "    \"Croatia flag\",\n",
        "    \"Cuba flag\",\n",
        "    \"Cyprus flag\",\n",
        "    \"Czechia flag\",\n",
        "    \"Democratic Republic of the Congo flag\",\n",
        "    \"Denmark flag\",\n",
        "    \"Djibouti flag\",\n",
        "    \"Dominica flag\",\n",
        "    \"Dominican Republic flag\",\n",
        "    \"East Timor flag\",\n",
        "    \"Ecuador flag\",\n",
        "    \"Egypt flag\",\n",
        "    \"El Salvador flag\",\n",
        "    \"Equatorial Guinea flag\",\n",
        "    \"Eritrea flag\",\n",
        "    \"Estonia flag\",\n",
        "    \"Eswatini flag\",\n",
        "    \"Ethiopia flag\",\n",
        "    \"Fiji flag\",\n",
        "    \"Finland flag\",\n",
        "    \"France flag\",\n",
        "    \"Gabon flag\",\n",
        "    \"Gambia flag\",\n",
        "    \"Georgia flag\",\n",
        "    \"Germany flag\",\n",
        "    \"Ghana flag\",\n",
        "    \"Greece flag\",\n",
        "    \"Grenada flag\",\n",
        "    \"Guatemala flag\",\n",
        "    \"Guinea flag\",\n",
        "    \"Guinea Bissau flag\",\n",
        "    \"Guyana flag\",\n",
        "    \"Haiti flag\",\n",
        "    \"Honduras flag\",\n",
        "    \"Hungary flag\",\n",
        "    \"Iceland flag\",\n",
        "    \"India flag\",\n",
        "    \"Indonesia flag\",\n",
        "    \"Iran flag\",\n",
        "    \"Iraq flag\",\n",
        "    \"Ireland flag\",\n",
        "    \"Israel flag\",\n",
        "    \"Italy flag\",\n",
        "    \"Jamaica flag\",\n",
        "    \"Japan flag\",\n",
        "    \"Jordan flag\",\n",
        "    \"Kazakhstan flag\",\n",
        "    \"Kenya flag\",\n",
        "    \"Kiribati flag\",\n",
        "    \"Korea North flag\",\n",
        "    \"Korea South flag\",\n",
        "    \"Kosovo flag\",\n",
        "    \"Kuwait flag\",\n",
        "    \"Kyrgyzstan flag\",\n",
        "    \"Laos flag\",\n",
        "    \"Latvia flag\",\n",
        "    \"Lebanon flag\",\n",
        "    \"Lesotho flag\",\n",
        "    \"Liberia flag\",\n",
        "    \"Libya flag\",\n",
        "    \"Liechtenstein flag\",\n",
        "    \"Lithuania flag\",\n",
        "    \"Luxembourg flag\",\n",
        "    \"Madagascar flag\",\n",
        "    \"Malawi flag\",\n",
        "    \"Malaysia flag\",\n",
        "    \"Maldives flag\",\n",
        "    \"Mali flag\",\n",
        "    \"Malta flag\",\n",
        "    \"Marshall Islands flag\",\n",
        "    \"Mauritania flag\",\n",
        "    \"Mauritius flag\",\n",
        "    \"Mexico flag\",\n",
        "    \"Micronesia flag\",\n",
        "    \"Moldova flag\",\n",
        "    \"Monaco flag\",\n",
        "    \"Mongolia flag\",\n",
        "    \"Montenegro flag\",\n",
        "    \"Morocco flag\",\n",
        "    \"Mozambique flag\",\n",
        "    \"Myanmar flag\",\n",
        "    \"Namibia flag\",\n",
        "    \"Nauru flag\",\n",
        "    \"Nepal flag\",\n",
        "    \"Netherlands flag\",\n",
        "    \"New Zealand flag\",\n",
        "    \"Nicaragua flag\",\n",
        "    \"Niger flag\",\n",
        "    \"Nigeria flag\",\n",
        "    \"North Macedonia flag\",\n",
        "    \"Norway flag\",\n",
        "    \"Oman flag\",\n",
        "    \"Pakistan flag\",\n",
        "    \"Palau flag\",\n",
        "    \"Panama flag\",\n",
        "    \"Papua New Guinea flag\",\n",
        "    \"Paraguay flag\",\n",
        "    \"Peru flag\",\n",
        "    \"Philippines flag\",\n",
        "    \"Poland flag\",\n",
        "    \"Portugal flag\",\n",
        "    \"Qatar flag\",\n",
        "    \"Republic of the Congo flag\",\n",
        "    \"Romania flag\",\n",
        "    \"Russia flag\",\n",
        "    \"Rwanda flag\",\n",
        "    \"Saint Kitts and Nevis flag\",\n",
        "    \"Saint Lucia flag\",\n",
        "    \"Saint Vincent and the Grenadines flag\",\n",
        "    \"Samoa flag\",\n",
        "    \"San Marino flag\",\n",
        "    \"Sao Tome and Principe flag\",\n",
        "    \"Saudi Arabia flag\",\n",
        "    \"Senegal flag\",\n",
        "    \"Serbia flag\",\n",
        "    \"Seychelles flag\",\n",
        "    \"Sierra Leone flag\",\n",
        "    \"Singapore flag\",\n",
        "    \"Slovakia flag\",\n",
        "    \"Slovenia flag\",\n",
        "    \"Solomon Islands flag\",\n",
        "    \"Somalia flag\",\n",
        "    \"South Africa flag\",\n",
        "    \"South Sudan flag\",\n",
        "    \"Spain flag\",\n",
        "    \"Sri Lanka flag\",\n",
        "    \"State of Palestine flag\",\n",
        "    \"Sudan flag\",\n",
        "    \"Suriname flag\",\n",
        "    \"Sweden flag\",\n",
        "    \"Switzerland flag\",\n",
        "    \"Syria flag\",\n",
        "    \"Taiwan flag\",\n",
        "    \"Tajikistan flag\",\n",
        "    \"Tanzania flag\",\n",
        "    \"Thailand flag\",\n",
        "    \"Togo flag\",\n",
        "    \"Tonga flag\",\n",
        "    \"Trinidad and Tobago flag\",\n",
        "    \"Tunisia flag\",\n",
        "    \"Turkey flag\",\n",
        "    \"Turkmenistan flag\",\n",
        "    \"Tuvalu flag\",\n",
        "    \"Uganda flag\",\n",
        "    \"Ukraine flag\",\n",
        "    \"United Arab Emirates flag\",\n",
        "    \"United Kingdom flag\",\n",
        "    \"United States of America flag\",\n",
        "    \"Uruguay flag\",\n",
        "    \"Uzbekistan flag\",\n",
        "    \"Vanuatu flag\",\n",
        "    \"Vatican City flag\",\n",
        "    \"Venezuela flag\",\n",
        "    \"Vietnam flag\",\n",
        "    \"Yemen flag\",\n",
        "    \"Zambia flag\",\n",
        "    \"Zimbabwe flag\",\n",
        "    \"Solid square of color\",\n",
        "    \"Creative flag\"\n",
        "]\n",
        "\n",
        "TOKENIZERS = {\n",
        "    32_000: 'c4_en',\n",
        "    250_000: 'mc4',\n",
        "}\n",
        "pp_txt = pp_builder.get_preprocess_fn(f'tokenize(max_len={SEQLEN}, model=\"{TOKENIZERS[VOCAB]}\", eos=\"sticky\", pad_value=1, inkey=\"text\")')\n",
        "txts = np.array([pp_txt({'text': text})['labels'] for text in texts])\n",
        "_, ztxt, out = model.apply({'params': params}, None, txts)\n",
        "\n",
        "print(txts.shape, ztxt.shape)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cg3puU7tAhQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run all image test\n",
        "import json\n",
        "\n",
        "with open(\"/content/drive/MyDrive/CS 229 Project/final_data.json\", 'r') as in_fp:\n",
        "  final_data = json.load(in_fp)\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/CS 229 Project/data/\"\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "# Get all of our images\n",
        "for folder_idx in range(10):\n",
        "  files = os.listdir(base_path + f\"{folder_idx}_test/\")\n",
        "  for file_path in files:\n",
        "    image_paths.append((base_path + f\"{folder_idx}_test/\", file_path))\n",
        "\n",
        "num_total = 0\n",
        "num_country = 0\n",
        "num_edge = 0\n",
        "num_country_correct = 0\n",
        "num_edge_correct = 0\n",
        "\n",
        "predictions = {}\n",
        "\n",
        "# Iteratively go through instead of doing all the images at once\n",
        "for image_duo in image_paths:\n",
        "  image_path = image_duo[1]\n",
        "  image = PIL.Image.open(image_duo[0] + image_duo[1])\n",
        "\n",
        "  pp_img = pp_builder.get_preprocess_fn(f'resize({RES})|value_range(-1, 1)')\n",
        "  img = np.array([pp_img({'image': np.array(image)})['image']])\n",
        "  zimg, _, out = model.apply({'params': params}, img, None)\n",
        "\n",
        "  probs = jax.nn.sigmoid(zimg @ ztxt.T * out['t'] + out['b'])\n",
        "\n",
        "  predicted_labels = []\n",
        "  corresponding_probs = []\n",
        "  for i in range(len(probs)):\n",
        "    prob = probs[i]\n",
        "    indices = np.where(prob > 0.6)[0]\n",
        "    predicted_labels.append([])\n",
        "    corresponding_probs.append([])\n",
        "    if indices.any():\n",
        "      for index in indices:\n",
        "        predicted_labels[i].append(texts[index])\n",
        "        corresponding_probs[i].append(float(probs[i, index]))\n",
        "    else:\n",
        "      predicted_labels[i].append(\"edge\")\n",
        "\n",
        "  prediction = predicted_labels[0][0]\n",
        "\n",
        "  if prediction == 'edge':\n",
        "    results = outlier_detector.predict([img],\n",
        "                                      outlier_type=\"instance\",\n",
        "                                      return_feature_score=True,\n",
        "                                      return_instance_score=True)\n",
        "    selected_threshold = 0.05\n",
        "    outlier = results[\"data\"][\"instance_score\"][0] >= selected_threshold\n",
        "\n",
        "  # Check vs truth\n",
        "  truth = final_data[image_path]\n",
        "  if prediction == \"edge\":\n",
        "    prediction = \"creative\" if outlier else \"bug\"\n",
        "\n",
        "  predictions[image_path] = prediction\n",
        "\n",
        "  if truth[\"country\"] not in [\"edge\", \"blank\"]:  # truth not an edge case\n",
        "    if prediction != \"bug\":  # pred not misclassified as false\n",
        "        num_country_correct += 1\n",
        "\n",
        "    num_country += 1\n",
        "  elif \"complexity\" in truth:\n",
        "    if prediction != \"bug\" and truth[\"complexity\"] > 1:\n",
        "      num_edge_correct += 1\n",
        "    elif prediction == \"bug\" and truth[\"complexity\"] <= 1:\n",
        "      num_edge_correct += 1\n",
        "    num_edge += 1"
      ],
      "metadata": {
        "id": "H_3guasbBxib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_total = num_country + num_edge\n",
        "num_correct = num_country_correct + num_edge_correct\n",
        "print(f\"{'Country Flags':<20}\", num_country_correct, '/', num_country, '=', num_country_correct / num_country)\n",
        "print(f\"{'Edge Case Flags':<20}\", num_edge_correct, '/', num_edge, '=', num_edge_correct / num_edge)\n",
        "print(f\"{'Total Test Accuracy':<20}\", num_correct, '/', num_total, '=', num_correct / num_total)"
      ],
      "metadata": {
        "id": "zPgWUAQyB452"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bug_correct = 0\n",
        "bug_total = 0\n",
        "\n",
        "creative_correct = 0\n",
        "creative_total = 0\n",
        "\n",
        "creative_flags_correct = []\n",
        "creative_flags_incorrect = []\n",
        "buggy_flags_correct = []\n",
        "buggy_flags_incorrect = []\n",
        "\n",
        "for img_path in predictions:\n",
        "  truth = final_data[img_path]\n",
        "  prediction = predictions[img_path]\n",
        "\n",
        "  if truth[\"country\"] in [\"edge\", \"blank\"] and \"complexity\" in truth:\n",
        "    if truth[\"complexity\"] > 1:\n",
        "      if prediction != \"bug\":\n",
        "        creative_correct += 1\n",
        "        creative_flags_correct.append(img_path)\n",
        "      else:\n",
        "        creative_flags_incorrect.append(img_path)\n",
        "\n",
        "      creative_total += 1\n",
        "    else:\n",
        "      if prediction == \"bug\":\n",
        "        bug_correct += 1\n",
        "        buggy_flags_correct.append(img_path)\n",
        "      else:\n",
        "        buggy_flags_incorrect.append(img_path)\n",
        "\n",
        "      bug_total += 1\n",
        "\n",
        "print(f\"{'Creative Flags':<20}\", creative_correct, '/', creative_total, '=', creative_correct / creative_total)\n",
        "print(f\"{'Buggy Flags':<20}\", bug_correct, '/', bug_total, '=', bug_correct / bug_total)\n",
        "print(f\"{'Edge Case Flags':<20}\", bug_correct + creative_correct, '/', bug_total + creative_total, '=', (bug_correct + creative_correct) / (bug_total + creative_total))"
      ],
      "metadata": {
        "id": "RPynXHf6B68G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo"
      ],
      "metadata": {
        "id": "PPazfdbZCCGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load and embed (randomly selected) images\n",
        "\n",
        "# Example using online resource instead of local data\n",
        "# !wget -q https://cdn.openai.com/multimodal-neurons/assets/apple/apple-ipod.jpg\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/CS 229 Project/data/\"\n",
        "\n",
        "data_folders = []\n",
        "image_paths = []\n",
        "\n",
        "NUM_IMAGES = 6\n",
        "\n",
        "# Roundabout way to get images since the directory structure is poor\n",
        "for i in range(NUM_IMAGES):\n",
        "  data_folders.append(random.randint(0, 9))\n",
        "\n",
        "for folder_idx in data_folders:\n",
        "  files = os.listdir(base_path + f\"{folder_idx}_test/\")\n",
        "  image_paths.append(base_path + f\"{folder_idx}_test/\" + random.sample(files, k=1)[0])\n",
        "\n",
        "images = [PIL.Image.open(fname) for fname in image_paths]\n",
        "\n",
        "pp_img = pp_builder.get_preprocess_fn(f'resize({RES})|value_range(-1, 1)')\n",
        "imgs = np.array([pp_img({'image': np.array(image)})['image'] for image in images])\n",
        "zimg, _, out = model.apply({'params': params}, imgs, None)\n",
        "\n",
        "print(data_folders)\n",
        "print(imgs.shape, zimg.shape)"
      ],
      "metadata": {
        "id": "xmuXfCfBjgeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predict flag classification\n",
        "# This is how to get all probabilities:\n",
        "print(f\"Learned temperature {out['t'].item():.1f}, learned bias: {out['b'].item():.1f}\\n\")\n",
        "probs = jax.nn.sigmoid(zimg @ ztxt.T * out['t'] + out['b'])\n",
        "\n",
        "predicted_labels = []\n",
        "corresponding_probs = []\n",
        "for i in range(len(probs)):\n",
        "  prob = probs[i]\n",
        "  indices = np.where(prob > 0.6)[0]\n",
        "  predicted_labels.append([])\n",
        "  corresponding_probs.append([])\n",
        "  if indices.any():\n",
        "    for index in indices:\n",
        "      predicted_labels[i].append(texts[index])\n",
        "      corresponding_probs[i].append(float(probs[i, index]))\n",
        "  else:\n",
        "    predicted_labels[i].append(\"edge\")\n",
        "\n",
        "# print(f\"{probs[0][0]:.1%} that image 0 is '{texts[0]}'\")\n",
        "# print(f\"{probs[0][1]:.1%} that image 0 is '{texts[1]}'\")\n",
        "\n",
        "# print(corresponding_probs)\n",
        "# print(len(corresponding_probs))"
      ],
      "metadata": {
        "id": "TIdAVw9VGEAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Use Outlier Detector\n",
        "# Set the base path to specify where we are working\n",
        "\n",
        "edge_cases = []\n",
        "edge_case_orig_indexes = []\n",
        "for i in range(len(predicted_labels)):\n",
        "  labels = predicted_labels[i]\n",
        "  if \"edge\" in labels:\n",
        "    edge_cases.append(imgs[i])\n",
        "    edge_case_orig_indexes.append(i)\n",
        "\n",
        "edge_cases = np.array(edge_cases)\n",
        "\n",
        "if edge_cases.size > 0:\n",
        "  results = outlier_detector.predict(edge_cases,\n",
        "                                    outlier_type=\"instance\",\n",
        "                                    return_feature_score=True,\n",
        "                                    return_instance_score=True)\n",
        "\n",
        "  print(results[\"data\"][\"instance_score\"])"
      ],
      "metadata": {
        "id": "zNeIbkWxiv2w",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Demo of Outlier Model's Reconstruction\n",
        "if edge_cases.size > 0:\n",
        "  selected_threshold = 0.05\n",
        "  outlier_indices = np.where(results['data'][\"instance_score\"] > selected_threshold)[0]\n",
        "  inlier_indices = np.where(results['data'][\"instance_score\"] <= selected_threshold)[0]\n",
        "\n",
        "  recon = outlier_detector.ae(tf.convert_to_tensor(edge_cases)).numpy()\n",
        "\n",
        "  outliers = [edge_case_orig_indexes[i] for i in outlier_indices]\n",
        "  inliers = [edge_case_orig_indexes[i] for i in inlier_indices]\n",
        "  print(\"Orig Indexes:\", edge_case_orig_indexes)\n",
        "  print(\"Outliers:\", [edge_case_orig_indexes[i] for i in outlier_indices])\n",
        "  print(\"Inliers:\", [edge_case_orig_indexes[i] for i in inlier_indices])\n",
        "\n",
        "  from alibi_detect.utils.visualize import plot_instance_score, plot_feature_outlier_image\n",
        "\n",
        "  if len(outlier_indices) > 0:\n",
        "    plot_feature_outlier_image(results,\n",
        "                              edge_cases,\n",
        "                              X_recon=recon,\n",
        "                              instance_ids=outlier_indices,  # pass a list with indices of instances to display\n",
        "                              n_channels=3,\n",
        "                              outliers_only=False)"
      ],
      "metadata": {
        "id": "5rkRacBji1bp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Pretty demo (code)\n",
        "from IPython.display import Javascript\n",
        "\n",
        "DEMO_IMG_SIZE = 96\n",
        "\n",
        "import base64\n",
        "import io\n",
        "\n",
        "def bv2rgb(bv_img):\n",
        "  return (bv_img * 127.5 + 127.5).astype(np.uint8)\n",
        "\n",
        "def html_img(*, enc_img=None, pixels=None, id=None, size=100, max_size=None, max_height=None, style=\"\"):\n",
        "  if enc_img is None and pixels is not None:\n",
        "    with io.BytesIO() as buf:\n",
        "      PIL.Image.fromarray(np.asarray(pixels)).save(buf, format=\"JPEG\")\n",
        "      enc_img = buf.getvalue()\n",
        "\n",
        "  img_data = base64.b64encode(np.ascontiguousarray(enc_img)).decode('ascii')\n",
        "\n",
        "  id_spec = f'id={id}' if id else ''\n",
        "  if size is not None:\n",
        "    style_spec = f'style=\"{style}; width: {size}px; height: {size}px\"'\n",
        "  elif max_size is not None:\n",
        "    style_spec = f'style=\"{style}; width: auto; height: auto; max-width: {max_size}px; max-height: {max_size}px;\"'\n",
        "  elif max_height is not None:\n",
        "    style_spec = f'style=\"{style}; object-fit: cover; width: auto; height: {max_height}px;\"'\n",
        "  else: style_spec = ''\n",
        "\n",
        "  return f'<img {id_spec} {style_spec} src=\"data:image/png;base64,{img_data}\"/>'\n",
        "\n",
        "\n",
        "def make_table(zimg, ztxt, out):\n",
        "  # The default learnable bias is a little conservative. Play around with it!\n",
        "  t, b = out['t'].item(), out['b'].item()\n",
        "  tempered_logits = zimg @ ztxt.T * t\n",
        "  probs = 1 / (1 + np.exp(-tempered_logits - b))\n",
        "  publish.javascript(f\"var logits = {tempered_logits.tolist()};\")\n",
        "\n",
        "  def color(p):\n",
        "    return mpl.colors.rgb2hex(mpl.cm.Greens(p / 2)) if p >= 0.01 else \"transparent\"\n",
        "\n",
        "  publish.javascript(f\"var cmap = {[color(x) for x in np.linspace(0, 1, 50)]};\")\n",
        "  def cell(x, iimg, itxt):\n",
        "    return f\"<td id=td_{iimg}_{itxt} style=background-color:{color(x)} class=pct><pre id=p_{iimg}_{itxt}>{x * 100:>4.0f}%</pre>\"\n",
        "\n",
        "  html = f'''\n",
        "  <p>\n",
        "  <label for=b>Bias value:</label>\n",
        "  <input id=b type=range min=-15 max=0 step=0.1 name=b value={b} style=vertical-align:middle>\n",
        "  <output id=value></output>\n",
        "  </p>\n",
        "  '''\n",
        "\n",
        "  html += \"<table>\\n\"\n",
        "  html += \"<tr>\"\n",
        "  html += \"\".join([f\"<td style='width:{DEMO_IMG_SIZE}px;line-height:0'>\" + html_img(pixels=bv2rgb(img), size=DEMO_IMG_SIZE) for img in imgs])\n",
        "  html += \"<td>\"\n",
        "  # for itxt, txt in enumerate(texts):\n",
        "  #   html += f\"<tr>\" + \"\".join([cell(probs[iimg, itxt], iimg, itxt) for iimg in range(len(imgs))]) + f\"<td class=txt>{txt}\"\n",
        "\n",
        "  publish.css(r\"\"\"\n",
        "  table {\n",
        "    border-collapse: collapse;\n",
        "  }\n",
        "\n",
        "  tr {\n",
        "    border: 1px transparent;\n",
        "  }\n",
        "\n",
        "  tr:nth-child(odd) {\n",
        "    background-color: #F5F5F5;\n",
        "  }\n",
        "\n",
        "  tr:hover {\n",
        "    background-color: lightyellow;\n",
        "    border: 1px solid black;\n",
        "  }\n",
        "\n",
        "  td.pct {\n",
        "    text-align: center;\n",
        "  }\n",
        "  \"\"\")\n",
        "  publish.html(html)\n",
        "\n",
        "  # JS code to compute and write all probs from the logits.\n",
        "  display(Javascript('''\n",
        "  function update(b) {\n",
        "    for(var iimg = 0; iimg < logits.length; iimg++) {\n",
        "      for(var itxt = 0; itxt < logits[iimg].length; itxt++) {\n",
        "        const el = document.getElementById(`p_${iimg}_${itxt}`);\n",
        "        const p = Math.round(100 / (1 + Math.exp(-logits[iimg][itxt] - b)));\n",
        "        const pad = p < 10.0 ? '  ' : p < 100.0 ? ' ' : ''\n",
        "        el.innerHTML = pad + (p).toFixed(0) + '%';\n",
        "\n",
        "        const td = document.getElementById(`td_${iimg}_${itxt}`);\n",
        "        const c = cmap[Math.round(p / 100 * (cmap.length - 1))];\n",
        "        td.style.backgroundColor = c;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  '''))\n",
        "\n",
        "  # JS code to connect the bias value slider\n",
        "  display(Javascript('''\n",
        "  const value = document.querySelector(\"#value\");\n",
        "  const input = document.querySelector(\"#b\");\n",
        "  value.textContent = input.value;\n",
        "  input.addEventListener(\"input\", (event) => {\n",
        "    value.textContent = event.target.value;\n",
        "    update(event.target.value);\n",
        "  });\n",
        "  '''))\n",
        "\n",
        "  # Make the cell output as large as the table to avoid annoying scrollbars.\n",
        "  display(Javascript(f'update({b})'))\n",
        "  display(Javascript('google.colab.output.resizeIframeToContent()'))"
      ],
      "metadata": {
        "id": "eolOc7vd_ZSj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Label Outliers\n",
        "\n",
        "outliers = [edge_case_orig_indexes[i] for i in outlier_indices]\n",
        "for outlier_idx in outliers:\n",
        "  predicted_labels[outlier_idx] = [\"creative\"]\n",
        "\n",
        "for inlier_idx in inliers:\n",
        "  predicted_labels[inlier_idx] = [\"bug\"]"
      ],
      "metadata": {
        "id": "LBdUrM-bj8A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pretty Demo (visuals)\n",
        "make_table(zimg, ztxt, out)\n",
        "print(predicted_labels)"
      ],
      "metadata": {
        "id": "mt5BIywzzA6c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}